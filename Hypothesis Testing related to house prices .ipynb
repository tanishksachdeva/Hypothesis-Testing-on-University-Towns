{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a hypothesis about the effect of recession on housing prices in university towns as compared to other towns\n",
    "## Tanishk Sachdeva\n",
    "To test the hypotheses that the university towns have their mean housing prices less effected by recessions, the notebook runs a t-test using ```scipy.stats.ttest_ind``` to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom vs the same price ratio for other towns. \n",
    " \n",
    "This is part of an assignment for the the online course [Introduction to Data Science in Python](https://www.coursera.org/learn/python-data-analysis). The data files used here can be found at:\n",
    "* The list of\n",
    "[university towns in the United States](https://en.wikipedia.org/wiki/List_of_college_towns#College_towns_in_the_United_States)\n",
    "from wikipedia has been copy and pasted into the file ```university_towns.txt``` in the repo. \n",
    "* The housing data from the \n",
    "[Zillow research data site](http://www.zillow.com/research/data/) stored in the file ```City_Zhvi_AllHomes.csv```.\n",
    "* The [GDP over time](http://www.bea.gov/national/index.htm#gdp) of the United States from the Bureau of Economic Analysis, US Department of Commerce, stored in the file ```gdplev.xls```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _university town_ is a city which has a high percentage of university students compared to the total population of the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of university towns: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Alabama</th>\n",
       "      <th>Auburn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jacksonville</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Livingston</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montevallo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Troy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuscaloosa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuskegee</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <th>Fairbanks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Arizona</th>\n",
       "      <th>Flagstaff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tempe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tucson</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Arkansas</th>\n",
       "      <th>Arkadelphia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conway</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fayetteville</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonesboro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnolia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monticello</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russellville</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Searcy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">California</th>\n",
       "      <th>Angwin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arcata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berkeley</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chico</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claremont</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cotati</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Davis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irvine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isla Vista</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Park, Los Angeles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Virginia</th>\n",
       "      <th>Wise</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesapeake</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Washington</th>\n",
       "      <th>Bellingham</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cheney</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ellensburg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pullman</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University District, Seattle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">West Virginia</th>\n",
       "      <th>Athens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buckhannon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairmont</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glenville</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huntington</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montgomery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morgantown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shepherdstown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Liberty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">Wisconsin</th>\n",
       "      <th>Appleton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eau Claire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Green Bay</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Crosse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madison</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Menomonie</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milwaukee</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oshkosh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platteville</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>River Falls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stevens Point</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waukesha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whitewater</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <th>Laramie</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(Alabama, Auburn), (Alabama, Florence), (Alabama, Jacksonville), (Alabama, Livingston), (Alabama, Montevallo), (Alabama, Troy), (Alabama, Tuscaloosa), (Alabama, Tuskegee), (Alaska, Fairbanks), (Arizona, Flagstaff), (Arizona, Tempe), (Arizona, Tucson), (Arkansas, Arkadelphia), (Arkansas, Conway), (Arkansas, Fayetteville), (Arkansas, Jonesboro), (Arkansas, Magnolia), (Arkansas, Monticello), (Arkansas, Russellville), (Arkansas, Searcy), (California, Angwin), (California, Arcata), (California, Berkeley), (California, Chico), (California, Claremont), (California, Cotati), (California, Davis), (California, Irvine), (California, Isla Vista), (California, University Park, Los Angeles), (California, Merced), (California, Orange), (California, Palo Alto), (California, Pomona), (California, Redlands), (California, Riverside), (California, Sacramento), (California, University District, San Bernardino), (California, San Diego), (California, San Luis Obispo), (California, Santa Barbara), (California, Santa Cruz), (California, Turlock), (California, Westwood, Los Angeles), (California, Whittier), (Colorado, Alamosa), (Colorado, Boulder), (Colorado, Durango), (Colorado, Fort Collins), (Colorado, Golden), (Colorado, Grand Junction), (Colorado, Greeley), (Colorado, Gunnison), (Colorado, Pueblo, Colorado), (Connecticut, Fairfield), (Connecticut, Middletown), (Connecticut, New Britain), (Connecticut, New Haven), (Connecticut, New London), (Connecticut, Storrs), (Connecticut, Willimantic), (Delaware, Dover), (Delaware, Newark), (Florida, Ave Maria), (Florida, Boca Raton), (Florida, Coral Gables), (Florida, DeLand), (Florida, Estero), (Florida, Gainesville), (Florida, Orlando), (Florida, Sarasota), (Florida, St. Augustine), (Florida, St. Leo), (Florida, Tallahassee), (Florida, Tampa), (Georgia, Albany), (Georgia, Athens), (Georgia, Atlanta), (Georgia, Carrollton), (Georgia, Demorest), (Georgia, Fort Valley), (Georgia, Kennesaw), (Georgia, Milledgeville), (Georgia, Mount Vernon), (Georgia, Oxford), (Georgia, Rome), (Georgia, Savannah), (Georgia, Statesboro), (Georgia, Valdosta), (Georgia, Waleska), (Georgia, Young Harris), (Hawaii, Manoa), (Idaho, Moscow), (Idaho, Pocatello), (Idaho, Rexburg), (Illinois, Carbondale), (Illinois, Champaign–Urbana), (Illinois, Charleston), (Illinois, DeKalb), (Illinois, Edwardsville), ...]\n",
       "\n",
       "[517 rows x 0 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_list_of_university_towns():\n",
    "    '''Returns a DataFrame with multi index consisting of the towns and the states from the \n",
    "    university_towns.txt list.'''\n",
    "    text_file = open(\"university_towns.txt\")\n",
    "    # Make a dictionary with key as the line number of the states that have \"[edit]\" after them \n",
    "    # and value as state name itself without \"[edit]\" \n",
    "    State = {idx: lines.strip().replace(\"[edit]\", \"\") \n",
    "             for idx,lines in enumerate(text_file) if \"edit\" in lines} \n",
    "    State = pd.Series(State) # Convert the dictionary to a series\n",
    "    university_towns = pd.read_csv(\"university_towns.txt\", sep = \"\\n\", header = None, \n",
    "                                   names = [\"RegionName\"])\n",
    "    university_towns[\"State\"] = State # Add the above series as a column in dataframe\n",
    "    university_towns = university_towns.fillna(method = 'ffill') # Forward fill for the \"State\" Column\n",
    "    # Drop all rows that has state names in the column \"RegionName\"\n",
    "    university_towns = university_towns.drop(State.index) \n",
    "    university_towns[\"RegionName\"] = list(map(lambda x: x.split(\"(\")[0].rstrip(), \n",
    "                                              university_towns[\"RegionName\"])) \n",
    "    university_towns = university_towns.set_index([\"State\", \"RegionName\"])\n",
    "    return university_towns\n",
    "print(\"List of university towns: \\n\")\n",
    "get_list_of_university_towns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _recession_ is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter before recession:  2008q2\n"
     ]
    }
   ],
   "source": [
    "def get_quarter_before_recession():\n",
    "    '''Returns the year and quarter of the recession start time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    GDP = pd.read_excel(\"gdplev.xls\", skiprows = 5)\n",
    "    GDP.drop(GDP.index[:214], inplace = True)\n",
    "    GDP.dropna(axis = 1, how = 'all', inplace = True)\n",
    "    GDP = GDP[[0,2]]\n",
    "    GDP.columns = [\"Quarters\", 'GDP in billions in current dollars']\n",
    "    GDP.set_index(\"Quarters\", inplace = True)\n",
    "    GDP_diff = GDP.diff() \n",
    "    for i, quarter in enumerate(GDP_diff.index):\n",
    "        if (GDP_diff.iloc[i+1] < 0).bool() and (GDP_diff.iloc[i+2] < 0).bool():\n",
    "            return quarter\n",
    "    return None  \n",
    "print(\"Quarter before recession: \", get_quarter_before_recession())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recession end:  2009q4\n"
     ]
    }
   ],
   "source": [
    "def get_recession_end():\n",
    "    '''Returns the year and quarter of the recession end time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    GDP = pd.read_excel(\"gdplev.xls\", skiprows = 5)\n",
    "    GDP.drop(GDP.index[:214], inplace = True)\n",
    "    GDP.dropna(axis = 1, how = 'all', inplace = True)\n",
    "    GDP = GDP[[0,2]]\n",
    "    GDP.columns = [\"Quarters\", 'GDP in billions in current dollars']\n",
    "    GDP.set_index(\"Quarters\", inplace = True)\n",
    "    GDP_diff = GDP.diff()\n",
    "    flag = 0\n",
    "    for i, quarter in enumerate(GDP_diff.index):\n",
    "        if (flag == 1) and (GDP_diff.iloc[i-1] > 0).bool() and (GDP_diff.iloc[i] > 0).bool():\n",
    "            return quarter\n",
    "        if (GDP_diff.iloc[i] < 0).bool() and (GDP_diff.iloc[i+1] < 0).bool():\n",
    "            flag = 1\n",
    "    return None\n",
    "print(\"Recession end: \", get_recession_end())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _recession bottom_ is the quarter within a recession which had the lowest GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recession bottom:  2009q2\n"
     ]
    }
   ],
   "source": [
    "def get_recession_bottom():\n",
    "    '''Returns the year and quarter of the recession bottom time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    GDP = pd.read_excel(\"gdplev.xls\", skiprows = 5)\n",
    "    GDP.drop(GDP.index[:214], inplace = True)\n",
    "    GDP.dropna(axis = 1, how = 'all', inplace = True)\n",
    "    GDP = GDP[[0,2]]\n",
    "    GDP.columns = [\"Quarters\", 'GDP in billions in current dollars']\n",
    "    GDP.set_index(\"Quarters\", inplace = True)\n",
    "    GDP_diff = GDP.diff()\n",
    "    flag = 0\n",
    "    for i, quarter in enumerate(GDP_diff.index):\n",
    "        if (flag == 1) and (GDP_diff.iloc[i] > 0).bool() and (GDP_diff.iloc[i+1] > 0).bool():\n",
    "            end_idx = i+1\n",
    "            break\n",
    "        if (flag == 0) and (GDP_diff.iloc[i] < 0).bool() and (GDP_diff.iloc[i+1] < 0).bool():\n",
    "            flag = 1\n",
    "            start_idx = i\n",
    "    GDP_recession = GDP.iloc[start_idx: end_idx + 1]\n",
    "    idx = GDP_recession.idxmin()\n",
    "    return idx[0]\n",
    "print(\"Recession bottom: \", get_recession_bottom())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _quarter_ is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: \n",
      " Index(['2000q1', '2000q2', '2000q3', '2000q4', '2001q1', '2001q2', '2001q3',\n",
      "       '2001q4', '2002q1', '2002q2', '2002q3', '2002q4', '2003q1', '2003q2',\n",
      "       '2003q3', '2003q4', '2004q1', '2004q2', '2004q3', '2004q4', '2005q1',\n",
      "       '2005q2', '2005q3', '2005q4', '2006q1', '2006q2', '2006q3', '2006q4',\n",
      "       '2007q1', '2007q2', '2007q3', '2007q4', '2008q1', '2008q2', '2008q3',\n",
      "       '2008q4', '2009q1', '2009q2', '2009q3', '2009q4', '2010q1', '2010q2',\n",
      "       '2010q3', '2010q4', '2011q1', '2011q2', '2011q3', '2011q4', '2012q1',\n",
      "       '2012q2', '2012q3', '2012q4', '2013q1', '2013q2', '2013q3', '2013q4',\n",
      "       '2014q1', '2014q2', '2014q3', '2014q4', '2015q1', '2015q2', '2015q3',\n",
      "       '2015q4', '2016q1', '2016q2', '2016q3'],\n",
      "      dtype='object')\n",
      "# Rows:  10730\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>2000q1</th>\n",
       "      <th>2000q2</th>\n",
       "      <th>2000q3</th>\n",
       "      <th>2000q4</th>\n",
       "      <th>2001q1</th>\n",
       "      <th>2001q2</th>\n",
       "      <th>2001q3</th>\n",
       "      <th>2001q4</th>\n",
       "      <th>2002q1</th>\n",
       "      <th>2002q2</th>\n",
       "      <th>...</th>\n",
       "      <th>2014q2</th>\n",
       "      <th>2014q3</th>\n",
       "      <th>2014q4</th>\n",
       "      <th>2015q1</th>\n",
       "      <th>2015q2</th>\n",
       "      <th>2015q3</th>\n",
       "      <th>2015q4</th>\n",
       "      <th>2016q1</th>\n",
       "      <th>2016q2</th>\n",
       "      <th>2016q3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n",
       "      <th>Adamsville</th>\n",
       "      <td>69033.333333</td>\n",
       "      <td>69166.666667</td>\n",
       "      <td>69800.000000</td>\n",
       "      <td>71966.666667</td>\n",
       "      <td>73466.666667</td>\n",
       "      <td>74000.000000</td>\n",
       "      <td>73333.333333</td>\n",
       "      <td>73100.000000</td>\n",
       "      <td>73333.333333</td>\n",
       "      <td>73133.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>77066.666667</td>\n",
       "      <td>75966.666667</td>\n",
       "      <td>71900.0</td>\n",
       "      <td>71666.666667</td>\n",
       "      <td>73033.333333</td>\n",
       "      <td>73933.333333</td>\n",
       "      <td>73866.666667</td>\n",
       "      <td>74166.666667</td>\n",
       "      <td>74933.333333</td>\n",
       "      <td>74700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabaster</th>\n",
       "      <td>122133.333333</td>\n",
       "      <td>123066.666667</td>\n",
       "      <td>123166.666667</td>\n",
       "      <td>123700.000000</td>\n",
       "      <td>123233.333333</td>\n",
       "      <td>125133.333333</td>\n",
       "      <td>127766.666667</td>\n",
       "      <td>127200.000000</td>\n",
       "      <td>127300.000000</td>\n",
       "      <td>128000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>147133.333333</td>\n",
       "      <td>147633.333333</td>\n",
       "      <td>148700.0</td>\n",
       "      <td>148900.000000</td>\n",
       "      <td>149566.666667</td>\n",
       "      <td>150366.666667</td>\n",
       "      <td>151733.333333</td>\n",
       "      <td>153466.666667</td>\n",
       "      <td>155100.000000</td>\n",
       "      <td>155850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albertville</th>\n",
       "      <td>73966.666667</td>\n",
       "      <td>72600.000000</td>\n",
       "      <td>72833.333333</td>\n",
       "      <td>74200.000000</td>\n",
       "      <td>75900.000000</td>\n",
       "      <td>76000.000000</td>\n",
       "      <td>72066.666667</td>\n",
       "      <td>73566.666667</td>\n",
       "      <td>76533.333333</td>\n",
       "      <td>76366.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>84033.333333</td>\n",
       "      <td>84766.666667</td>\n",
       "      <td>86800.0</td>\n",
       "      <td>88466.666667</td>\n",
       "      <td>89500.000000</td>\n",
       "      <td>90233.333333</td>\n",
       "      <td>91366.666667</td>\n",
       "      <td>92000.000000</td>\n",
       "      <td>92466.666667</td>\n",
       "      <td>92200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arab</th>\n",
       "      <td>83766.666667</td>\n",
       "      <td>81566.666667</td>\n",
       "      <td>81333.333333</td>\n",
       "      <td>82966.666667</td>\n",
       "      <td>84200.000000</td>\n",
       "      <td>84533.333333</td>\n",
       "      <td>81666.666667</td>\n",
       "      <td>83900.000000</td>\n",
       "      <td>87266.666667</td>\n",
       "      <td>87700.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>113366.666667</td>\n",
       "      <td>111700.000000</td>\n",
       "      <td>111600.0</td>\n",
       "      <td>110166.666667</td>\n",
       "      <td>109433.333333</td>\n",
       "      <td>110900.000000</td>\n",
       "      <td>112233.333333</td>\n",
       "      <td>110033.333333</td>\n",
       "      <td>110100.000000</td>\n",
       "      <td>112000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ardmore</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>140533.333333</td>\n",
       "      <td>139566.666667</td>\n",
       "      <td>140900.0</td>\n",
       "      <td>143233.333333</td>\n",
       "      <td>143000.000000</td>\n",
       "      <td>144600.000000</td>\n",
       "      <td>143966.666667</td>\n",
       "      <td>142566.666667</td>\n",
       "      <td>143233.333333</td>\n",
       "      <td>141950.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            2000q1         2000q2         2000q3  \\\n",
       "State   RegionName                                                 \n",
       "Alabama Adamsville    69033.333333   69166.666667   69800.000000   \n",
       "        Alabaster    122133.333333  123066.666667  123166.666667   \n",
       "        Albertville   73966.666667   72600.000000   72833.333333   \n",
       "        Arab          83766.666667   81566.666667   81333.333333   \n",
       "        Ardmore                NaN            NaN            NaN   \n",
       "\n",
       "                            2000q4         2001q1         2001q2  \\\n",
       "State   RegionName                                                 \n",
       "Alabama Adamsville    71966.666667   73466.666667   74000.000000   \n",
       "        Alabaster    123700.000000  123233.333333  125133.333333   \n",
       "        Albertville   74200.000000   75900.000000   76000.000000   \n",
       "        Arab          82966.666667   84200.000000   84533.333333   \n",
       "        Ardmore                NaN            NaN            NaN   \n",
       "\n",
       "                            2001q3         2001q4         2002q1  \\\n",
       "State   RegionName                                                 \n",
       "Alabama Adamsville    73333.333333   73100.000000   73333.333333   \n",
       "        Alabaster    127766.666667  127200.000000  127300.000000   \n",
       "        Albertville   72066.666667   73566.666667   76533.333333   \n",
       "        Arab          81666.666667   83900.000000   87266.666667   \n",
       "        Ardmore                NaN            NaN            NaN   \n",
       "\n",
       "                            2002q2    ...            2014q2         2014q3  \\\n",
       "State   RegionName                    ...                                    \n",
       "Alabama Adamsville    73133.333333    ...      77066.666667   75966.666667   \n",
       "        Alabaster    128000.000000    ...     147133.333333  147633.333333   \n",
       "        Albertville   76366.666667    ...      84033.333333   84766.666667   \n",
       "        Arab          87700.000000    ...     113366.666667  111700.000000   \n",
       "        Ardmore                NaN    ...     140533.333333  139566.666667   \n",
       "\n",
       "                       2014q4         2015q1         2015q2         2015q3  \\\n",
       "State   RegionName                                                           \n",
       "Alabama Adamsville    71900.0   71666.666667   73033.333333   73933.333333   \n",
       "        Alabaster    148700.0  148900.000000  149566.666667  150366.666667   \n",
       "        Albertville   86800.0   88466.666667   89500.000000   90233.333333   \n",
       "        Arab         111600.0  110166.666667  109433.333333  110900.000000   \n",
       "        Ardmore      140900.0  143233.333333  143000.000000  144600.000000   \n",
       "\n",
       "                            2015q4         2016q1         2016q2    2016q3  \n",
       "State   RegionName                                                          \n",
       "Alabama Adamsville    73866.666667   74166.666667   74933.333333   74700.0  \n",
       "        Alabaster    151733.333333  153466.666667  155100.000000  155850.0  \n",
       "        Albertville   91366.666667   92000.000000   92466.666667   92200.0  \n",
       "        Arab         112233.333333  110033.333333  110100.000000  112000.0  \n",
       "        Ardmore      143966.666667  142566.666667  143233.333333  141950.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_housing_data_to_quarters():\n",
    "    '''Converts the housing data to quarters and returns it as mean \n",
    "    values in a dataframe. This dataframe should be a dataframe with\n",
    "    columns for 2000q1 through 2016q3, and should have a multi-index\n",
    "    in the shape of [\"State\",\"RegionName\"].\n",
    "    \n",
    "    Note: Quarters are defined in the assignment description, they are\n",
    "    not arbitrary three month periods.\n",
    "    \n",
    "    The resulting dataframe should have 67 columns, and 10,730 rows.\n",
    "    '''\n",
    "    all_homes = pd.read_csv(\"City_Zhvi_AllHomes.csv\")\n",
    "    \n",
    "    states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', \n",
    "              'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', \n",
    "              'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', \n",
    "              'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', \n",
    "              'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', \n",
    "              'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', \n",
    "              'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', \n",
    "              'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', \n",
    "              'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', \n",
    "              'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', \n",
    "              'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', \n",
    "              'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', \n",
    "              'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', \n",
    "              'VA': 'Virginia'}\n",
    "    # Replaces the abbreviations with the names of the states\n",
    "    all_homes[\"State\"].replace(states, inplace = True) \n",
    "    all_homes = all_homes.set_index([\"State\",\"RegionName\"])\n",
    "    all_homes = all_homes.iloc[:, 49:250] # Discards irrelavant columns\n",
    "    \n",
    "    def quarters(col):\n",
    "        if col.endswith((\"01\", \"02\", \"03\")):\n",
    "            s = col[:4] + \"q1\"\n",
    "        elif col.endswith((\"04\", \"05\", \"06\")):\n",
    "            s = col[:4] + \"q2\"\n",
    "        elif col.endswith((\"07\", \"08\", \"09\")):\n",
    "            s = col[:4] + \"q3\"\n",
    "        else:\n",
    "            s = col[:4] + \"q4\"\n",
    "        return s  \n",
    "    # Groups the monthly columns into quarters using mean value of the four monthly columns\n",
    "    housing = all_homes.groupby(quarters, axis = 1).mean() \n",
    "    housing = housing.sort_index()\n",
    "    return housing\n",
    "housing = convert_housing_data_to_quarters()\n",
    "print(\"Columns: \\n\", housing.columns)\n",
    "print(\"# Rows: \", len(housing))\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis**: University towns have their mean housing prices less effected by recessions. Running a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom. (`price_ratio=quarter_before_recession/recession_bottom`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.002724063704761164, 'university town')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_ttest():\n",
    "    '''First creates new data showing the decline or growth of housing prices\n",
    "    between the recession start and the recession bottom. Then runs a ttest\n",
    "    comparing the university town values to the non-university towns values, \n",
    "    return whether the alternative hypothesis (that the two groups are the same)\n",
    "    is true or not as well as the p-value of the confidence. \n",
    "    \n",
    "    Returns the tuple (different, p, better) where different=True if the t-test is\n",
    "    True at a p<0.01 (we reject the null hypothesis), or different=False if \n",
    "    otherwise (we cannot reject the null hypothesis). The variable p is the \n",
    "    exact p value returned from scipy.stats.ttest_ind(). The value for better is \n",
    "    either \"university town\" or \"non-university town\" depending on which has a \n",
    "    lower mean price ratio (which is equivilent to a reduced market loss).'''\n",
    "    housing = convert_housing_data_to_quarters()\n",
    "    university_towns = get_list_of_university_towns()\n",
    "    quarter_before_recession = get_quarter_before_recession()    \n",
    "    recession_bottom = get_recession_bottom()\n",
    "    housing = housing[[quarter_before_recession, recession_bottom]]\n",
    "    housing[\"price_ratio\"] = housing[quarter_before_recession].div(housing[recession_bottom])\n",
    "    housing = housing.dropna()\n",
    "    university_housing = pd.merge(university_towns, housing, how = \"inner\", \n",
    "                                  left_index = True, right_index = True)\n",
    "    non_university_housing = housing[~housing.index.isin(university_housing.index)]\n",
    "    from scipy import stats\n",
    "    t_stat, p_value = stats.ttest_ind(university_housing[\"price_ratio\"], \n",
    "                                      non_university_housing[\"price_ratio\"])\n",
    "    different = True\n",
    "    if p_value < 0.01:\n",
    "        different = True\n",
    "    else:\n",
    "        different = False\n",
    "    if t_stat < 0:\n",
    "        better = \"university town\"\n",
    "    else:\n",
    "        better = \"non-university town\"\n",
    "    return (different, p_value, better)\n",
    "run_ttest()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "course_slug": "python-data-analysis",
   "graded_item_id": "Il9Fx",
   "launcher_item_id": "TeDW0",
   "part_id": "WGlun"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
